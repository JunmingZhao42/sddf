/* Pancake heap layout

              pancake heap 1024*9 bytes
             +--------------------------+
      [0..7] | eth regs addr            |
             +--------------------------+
     [9..31] | rx_queue {               |
             | free buffer ptr          +---->
             | active buffer ptr        +----> shared mem with virt_rx
             | queue capacity           |
             |}                         |
             +--------------------------+
    [32..55] | tx queue {               |
             | free buffer ptr          +---->
             | active buffer ptr        +----> shared mem with virt_tx
             | queue capacity           |
             |}                         |
             +--------------------------+
  [56..4175] | hw_ring tx {             |
             |  tail index              |
             |  head index              |
             |  capacity                |
             |  buffers meta data       |
             |  buffer descriptors ptr  +----> shared mem with device
             | }                        |
             +--------------------------+
[4176..8295] | hw_ring rx {             |
             |  tail index              |
             |  head index              |
             |  capacity                |
             |  buffers meta data       |
             |  buffer descriptors ptr  +----> shared mem with device
             | }                        |
             +--------------------------+
 [8296..9216]| dynamic heap             |
             |                          |
             |                          |
             |                          |
             |                          |
             |                          |
             +--------------------------+
 */

#define IRQ_CH 0
#define TX_CH  1
#define RX_CH  2

#define MAX_COUNT       256

#define ETH_REGS        (lds 1 @base)
#define RX_QUEUE_ADDR   (@base + 3 * @biw)
#define TX_QUEUE_ADDR   (@base + 6 * @biw)
#define RX_MDATA_ADDR   (@base + 32 * @biw)
#define TX_MDATA_ADDR   (@base + 576 * @biw)

#define RX_MDATA_ADDR_IDX(idx)  (RX_MDATA_ADDR + idx * NET_BUFF_DESC_SIZE)
#define TX_MDATA_ADDR_IDX(idx)  (TX_MDATA_ADDR + idx * NET_BUFF_DESC_SIZE)

#define DESCRIPTROR_SIZE    8
#define HW_RING_SIZE        (4 * @biw)
#define HW_RING_RX          (@base + 9 * @biw)
#define HW_RING_TX          (@base + 9 * @biw + HW_RING_SIZE)
#define ETH_USER_BASE       (@base + @biw * 1536)

// Todo: change this hack once !st16/!ld16 is supported in pancake
#define update_ring_slot(descr, idx, phys, len, stat)       \
    var dst_addr = descr + idx * DESCRIPTROR_SIZE;          \
    var descriptor = (stat << 16) | len;                    \
    !st32 dst_addr + 4, phys;                               \
    THREAD_MEMORY_RELEASE()                                 \
    !st32 dst_addr, descriptor;                             \

fun main () {
    rx_provide();
    tx_provide();
    return 0;
}

/*
 * `rx_return()`: Transfer "active buffer" from device to `virt_rx`
 * 1. check if `hw_ring_rx` is not empty; if not then exit
 * 2. get a buffer from `head` slot of `hw_ring_rx`, make sure its status is non-empty; if not then exit
 * 3. increment `hw_ring_rx` head, enqueue the buffer to `rx_active`
 * 4. if `rx_active` requires signalling, cancel the signal and notify `virt_rx` via microkit
 */
fun rx_return() {
    var packets_transferred = false;
    var rx_queue = lds {1,1,1} RX_QUEUE_ADDR;
    var rx_active = rx_queue.1;
    var capacity = rx_queue.2;

    while (true) {
        var hw_ring_rx = lds {1,1,1,1} HW_RING_RX;
        var hw_tail = hw_ring_rx.0;
        var hw_head = hw_ring_rx.1;
        if (queue_empty(hw_head, hw_tail)) {
            break;
        }
        // If buffer slot is still empty, we have processed all packets the device has filled
        var hw_capacity = hw_ring_rx.2;
        pnk_modulo(idx, hw_head, hw_capacity)

        // volatile struct descriptor *d = &(hw_ring_rx->descr[hw_ring_rx->head]);
        var descr = hw_ring_rx.3;
        var dscr_addr = descr + idx * DESCRIPTROR_SIZE; // this is an shared mem address
        var descriptor = 0;
        !ld32 descriptor, dscr_addr;

        var stat = (descriptor >> 16) & MASK_16;
        if (stat & RXD_EMPTY) {
            break;
        }

        var mdata_buff = RX_MDATA_ADDR_IDX(idx);
        st mdata_buff + @biw, (descriptor & MASK_16);
        var 1 err = net_enqueue(rx_active, capacity, mdata_buff);

        packets_transferred = true;
        hw_head = hw_head + 1;
        st HW_RING_RX, <hw_tail, hw_head, hw_capacity, descr>;
    }

    net_require_signal(signal, rx_active)
    if (packets_transferred && signal) {
        net_cancel_signal(rx_active)
        microkit_notify(RX_CH)
    }
    return 0;
}

/*
 * `rx_provide()`: Transfer "free buffer" from `virt_rx` to device
 * 1. check if `hw_ring_rx` is not full, and `rx_queue` is not empty;  if not then exit
 * 2. dequeue a buffer from `rx_free`, update the buffer stat
 * 3. update the tail slot of `hw_ring_rx` to this buffer, increment `hw_ring_rx` tail
 * 4. set device `rdar` register
 * 5. set `rx_free` as require signalling if `hw_ring_rx` is not full
 * 6. recheck (1), process more if needed
*/
fun rx_provide() {
    var reprocess = true;
    var rx_queue = lds {1,1,1} RX_QUEUE_ADDR;
    var rx_free = rx_queue.0;
    var capacity = rx_queue.2;
    var eth = ETH_REGS;

    while (reprocess) {
        while (true) {
            var hw_ring_rx = lds {1,1,1,1} HW_RING_RX;
            var hw_tail = hw_ring_rx.0;
            var hw_head = hw_ring_rx.1;
            var hw_capacity = hw_ring_rx.2;
            net_queue_empty(empty, rx_free)
            if (queue_full(hw_head, hw_tail, hw_capacity) || empty) {
                break;
            }
            THREAD_MEMORY_ACQUIRE()

            var stack_buff = ETH_USER_BASE;
            var 1 err = net_dequeue(rx_free, capacity, stack_buff);
            var net_buffer = lds {1,1} stack_buff;

            var stat = RXD_EMPTY; // uint16_t
            pnk_modulo(idx, hw_tail, hw_capacity)
            if (idx + 1 == hw_capacity) {
                stat = stat | WRAP;
            }

            var mdata_buff = RX_MDATA_ADDR_IDX(idx);
            var io_or_offset = net_buffer.0;
            var len = net_buffer.1;
            !stw mdata_buff, io_or_offset;
            !stw mdata_buff + @biw, len;

            var descr = hw_ring_rx.3;
            update_ring_slot(descr, idx, io_or_offset, 0, stat)

            hw_tail = hw_tail + 1;
            st HW_RING_RX, <hw_tail, hw_head, hw_capacity, descr>;
            set_eth_rdar(RDAR_RDAR, eth)
        }

        // Only request a notification from virtualiser if HW ring not full
        var hw_ring_rx = lds {1,1,1,1} HW_RING_RX;
        var full = queue_full(hw_ring_rx.1, hw_ring_rx.0, hw_ring_rx.2);
        if (!full) {
            net_request_signal(rx_free)
        } else {
            net_cancel_signal(rx_free)
        }

        reprocess = false;

        net_queue_empty(empty, rx_free)
        if ((!empty) && (!full)) {
            net_cancel_signal(rx_free)
            reprocess = true;
        }
    }
    return 0;
}

/*
 * `tx_provide()`: Transfer "active buffer" from `virt_tx` to device
 * 1. check if `hw_ring_tx` is not full, and `tx_active` is not empty; if not then exit
 * 2. dequeue a buffer from `tx_active`, update the buffer stat
 * 3. update the tail slot of `hw_ring_tx` to this buffer, increment `hw_ring_tx` tail
 * 4. set device `tdar` register
 * 5. set `tx_active` as require signalling
 * 6. recheck (1), process more if needed
 */
fun tx_provide() {
    var reprocess = true;
    var tx_queue = lds {1,1,1} TX_QUEUE_ADDR;
    var tx_active = tx_queue.1;
    var capacity = tx_queue.2;
    var eth = ETH_REGS;

    while (reprocess) {
        while (true) {
            var hw_ring_tx = lds {1,1,1,1} HW_RING_TX;
            var hw_tail = hw_ring_tx.0;
            var hw_head = hw_ring_tx.1;
            var hw_capacity = hw_ring_tx.2;
            net_queue_empty(empty, tx_active)
            if (queue_full(hw_head, hw_tail, hw_capacity) || empty) {
                break;
            }

            var stack_buff = ETH_USER_BASE;
            var 1 err = net_dequeue(tx_active, capacity, stack_buff);
            var net_buffer = lds {1,1} stack_buff;

            var stat = TXD_READY | TXD_ADDCRC | TXD_LAST; // uint16_t
            pnk_modulo(idx, hw_tail, hw_capacity)
            if (idx + 1 == hw_capacity) {
                stat = stat | WRAP;
            }

            var mdata_buff = TX_MDATA_ADDR_IDX(idx);
            var io_or_offset = net_buffer.0;
            var len = net_buffer.1;
            !stw mdata_buff, io_or_offset;
            !stw mdata_buff + @biw, len;

            var descr = hw_ring_tx.3;
            update_ring_slot(descr, idx, io_or_offset, len, stat)

            hw_tail = hw_tail + 1;
            st HW_RING_TX, <hw_tail, hw_head, hw_capacity, descr>;
            set_eth_tdar(TDAR_TDAR, eth)
        }

        net_request_signal(tx_active)
        reprocess = false;

        var hw_ring_tx = lds {1,1,1,1} HW_RING_TX;
        var full = queue_full(hw_ring_tx.1, hw_ring_tx.0, hw_ring_tx.2);
        net_queue_empty(empty, tx_active)
        if ((!full) && (!empty)) {
            net_cancel_signal(tx_active)
            reprocess = true;
        }
    }
    return 0;
}

/*
 * `tx_return()`: Transfer "free buffer" from device to `virt_tx`
 * 1. check  if `hw_ring_tx` is not empty; if not then exit
 * 2. get a buffer from `head` slot of `hw_ring_tx`, make sure it's been processed by the device; if not then exit
 * 3. increment `hw_ring_tx` head, reset the buffer length, enqueue the buffer to `tx_free`
 * 4. if `rx_free` requires signalling, cancel the signal and notify `virt_tx` via microkit
 */
fun tx_return() {
    var enqueued = false;
    var tx_queue = lds {1,1,1} TX_QUEUE_ADDR;
    var tx_free = tx_queue.0;
    var capacity = tx_queue.2;

    while (true) {
        var hw_ring_tx = lds {1,1,1,1} HW_RING_TX;
        var hw_tail = hw_ring_tx.0;
        var hw_head = hw_ring_tx.1;
        if (queue_empty(hw_head, hw_tail)) {
            break;
        }

        THREAD_MEMORY_ACQUIRE()

        // Ensure that this buffer has been sent by the device
        var hw_capacity = hw_ring_tx.2;
        var descr = hw_ring_tx.3;
        pnk_modulo(idx, hw_head, hw_capacity)
        var dscr_addr = descr + idx * DESCRIPTROR_SIZE;
        var descriptor = 0;
        !ld32 descriptor, dscr_addr;

        var stat = (descriptor >> 16) & MASK_16;
        if (stat & TXD_READY) {
            break;
        }

        var mdata_buff = TX_MDATA_ADDR_IDX(idx);
        st mdata_buff + @biw, 0;
        var 1 err = net_enqueue(tx_free, capacity, mdata_buff);

        enqueued = true;
        hw_head = hw_head + 1;
        st HW_RING_TX, <hw_tail, hw_head, hw_capacity, descr>;
    }

    net_require_signal(signal, tx_free)
    if (enqueued && signal) {
        net_cancel_signal(tx_free)
        microkit_notify(TX_CH)
    }
    return 0;
}

fun handle_irq() {
    var eth = ETH_REGS;
    get_eth_eir(eir, eth)

    var e = eir & IRQ_MASK;
    set_eth_eir(e, eth)

    while (e & IRQ_MASK) {
        if (e & NETIRQ_TXF) {
            tx_return();
            tx_provide();
        }
        if (e & NETIRQ_RXF) {
            rx_return();
            rx_provide();
        }
        // TODO: sddf_dprintf("ETH|ERROR: System bus/uDMA\n");
        // if (e & NETIRQ_EBERR) {
        //    skip;
        // }
        get_eth_eir(eir, eth)
        e = eir & IRQ_MASK;
        set_eth_eir(e, eth)
    }
    return 0;
}

export fun notified(1 channel) {
    if (channel == IRQ_CH) {
        handle_irq();
        /*
         * Delay calling into the kernel to ack the IRQ until the next loop
         * in the microkit event handler loop.
         */
        microkit_deferred_irq_ack(channel)
        return 0;
    }

    if (channel == RX_CH) {
        rx_provide();
        return 0;
    }

    if (channel == TX_CH) {
        tx_provide();
        return 0;
    }

    return -1;
}